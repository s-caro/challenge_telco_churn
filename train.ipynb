{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d443e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efde3ac",
   "metadata": {},
   "source": [
    "# Importo dataset di train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d52d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"train.csv\")\n",
    "test_dataset = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782eb2ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non vi sono valori nulli nel dataset\n",
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60395b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non vi sono valori nulli nel dataset\n",
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11aab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check on null values\n",
    "train_dataset.isna().sum()\n",
    "test_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e20221",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customerId è unico per ogni riga, quindi non influenza 'Churn' per questo motivo possiamo dropparlo\n",
    "train_dataset = train_dataset.drop('customerID', axis=1)\n",
    "test_dataset = test_dataset.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf70a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a86672",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# il gender non sembra avere un effetto su churn, però prima di droppare la colonna faccio l'encoding e vedo la correlazione\n",
    "\n",
    "sns.countplot(x=train_dataset[\"gender\"],hue=train_dataset[\"Churn\"],palette='mako');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbc041",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaiamo un dizionario che associa ad ogni colonna del dataset i valori che può assumere la colonna\n",
    "\n",
    "def get_uniques(df, columns):\n",
    "    return {column: list(df[column].unique()) for column in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47549afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nel dizionario lasciamo solo le colonne che hanno valori di tipo \"object\", quindi escludiamo i valori numerici\n",
    "# poiché in questa parte ci occupiamo dell'encoding, quindi i valori numerici sono già ok\n",
    "\n",
    "def get_categorical_columns(df):\n",
    "    return [column for column in df.columns if df.dtypes[column] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e27a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adesso posso vedere i possibili valori che possono comparire in ogni colonna\n",
    "\n",
    "get_uniques(train_dataset, get_categorical_columns(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4431bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Total charges' è una colonna che contiene numeri ma sono encoded come stringhe, devono essere convertiti\n",
    "# train_dataset['TotalCharges'].astype(np.float), questo comando da un errore perché non tutti i valori presenti nella colonna\n",
    "# sono numeri encoded come stringhe, ci sono dei valori nulli rappresentati come spazi ''\n",
    "sorted(train_dataset['TotalCharges'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sostituisco le stringhe vuote con valori nulli\n",
    "train_dataset['TotalCharges'] = train_dataset['TotalCharges'].replace(' ', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conto quanti righe presentano il valore null per capire come trattare la colonna\n",
    "train_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i valori sono in tutto 7, è un valore piccolo rispetto al numero totale di righe, posso droppare queste righe\n",
    "train_dataset.dropna(how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adesso le stringhe possono essere trasformate in float\n",
    "train_dataset['TotalCharges'] = train_dataset['TotalCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripeto tutto anche per il test_dataset\n",
    "get_uniques(test_dataset, get_categorical_columns(test_dataset))\n",
    "\n",
    "# sostituisco le stringhe vuote con valori nulli\n",
    "test_dataset['TotalCharges'] = test_dataset['TotalCharges'].replace(' ', np.NaN)\n",
    "\n",
    "# conto quanti righe presentano il valore null per capire come trattare la colonna\n",
    "test_dataset.isna().sum()\n",
    "\n",
    "# i valori sono in tutto 3, è un valore piccolo rispetto al numero totale di righe, posso droppare queste righe\n",
    "test_dataset.dropna(how = 'any', inplace = True)\n",
    "\n",
    "# adesso le stringhe possono essere trasformate in float\n",
    "test_dataset['TotalCharges'] = test_dataset['TotalCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaff2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_uniques(train_dataset, get_categorical_columns(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_uniques(test_dataset, get_categorical_columns(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55380510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nelle colonne 'MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies'\n",
    "# compaiono 3 possibili valori 'No, Yes, No internet service/ No phone service', non avere 'phone service o internet service' equivale\n",
    "# a non avere il servizio specifico, per cui si possono accorpare\n",
    "\n",
    "train_dataset['MultipleLines'] = train_dataset['MultipleLines'].replace('No phone service', 'No')\n",
    "\n",
    "train_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "      'TechSupport', 'StreamingTV', 'StreamingMovies']] = train_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                                                                'TechSupport', 'StreamingTV', 'StreamingMovies']].replace('No internet service', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39439ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faccio lo stesso per il test_dataset\n",
    "\n",
    "test_dataset['MultipleLines'] = test_dataset['MultipleLines'].replace('No phone service', 'No')\n",
    "\n",
    "test_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "      'TechSupport', 'StreamingTV', 'StreamingMovies']] = test_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                                                                'TechSupport', 'StreamingTV', 'StreamingMovies']].replace('No internet service', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e97210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividiamo le features in 3 tipologie: binary, ordinal e nominal. Per ognuna verrà fatto un encoding differente\n",
    "# questo passaggio non è necessario per l'encoding, però mi piace questo ordine mentale e quindi ho creato le 3 liste e \n",
    "# faccio l'encoding una per volta, spero non sia un grande problema\n",
    "# la maniera più semplice sarebbe stato creare un'unica lista con i nomi delle colonne e fare l'encoding utilizzando quella singola lista\n",
    " \n",
    "binary_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                   'StreamingTV', 'StreamingMovies', 'PaperlessBilling']\n",
    "\n",
    "\n",
    "ordinal_features = ['InternetService', 'Contract']\n",
    "\n",
    "nominal_features = ['PaymentMethod']\n",
    "\n",
    "# non è una feature ma la target column\n",
    "\n",
    "target_column = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01421324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding per le colonne che contengono valori binari\n",
    "\n",
    "labelEncoder_X = LabelEncoder()\n",
    "for element in binary_features:\n",
    "    train_dataset[element] = labelEncoder_X.fit_transform(train_dataset[element])\n",
    "    \n",
    "# encoding per le colonne che contengono valori ordinal\n",
    "\n",
    "labelEncoder_X = LabelEncoder()\n",
    "for element in ordinal_features:\n",
    "    train_dataset[element] = labelEncoder_X.fit_transform(train_dataset[element])\n",
    "\n",
    "# encoding per le colonne che contengono valori nominal\n",
    "\n",
    "labelEncoder_X = LabelEncoder()\n",
    "for element in nominal_features:\n",
    "    train_dataset[element] = labelEncoder_X.fit_transform(train_dataset[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3da157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripeto tutto anche per il test_dataset\n",
    "\n",
    "labelEncoder_X = LabelEncoder()\n",
    "for element in binary_features:\n",
    "    test_dataset[element] = labelEncoder_X.fit_transform(test_dataset[element])\n",
    "    \n",
    "labelEncoder_X = LabelEncoder()\n",
    "for element in ordinal_features:\n",
    "    test_dataset[element] = labelEncoder_X.fit_transform(test_dataset[element])\n",
    "    \n",
    "labelEncoder_X = LabelEncoder()\n",
    "for element in nominal_features:\n",
    "    test_dataset[element] = labelEncoder_X.fit_transform(test_dataset[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e97261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eseguo l'encoding anche per la colonna target, sia per il train_dataset che per il test_dataset\n",
    "\n",
    "train_dataset[target_column] = labelEncoder_X.fit_transform(train_dataset[target_column])\n",
    "\n",
    "test_dataset[target_column] = labelEncoder_X.fit_transform(test_dataset[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdadc57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# una volta fatto l'encoding è possibile visualizzare l'heatmap con tutte le feature\n",
    "# per capire se vi sono altre colonne che è possibile droppare vediamo la correlazione tra le diverse colonne\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "correlation = train_dataset.corr()\n",
    "sns.heatmap(correlation, annot = True, linewidth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# come detto precedentemente il gendere non influenza churn, let's drop gender column\n",
    "train_dataset = train_dataset.drop('gender', axis=1)\n",
    "test_dataset = test_dataset.drop('gender', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df7cd6",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_dataset['Churn']          \n",
    "X_train = train_dataset.drop(['Churn'], axis=1)  \n",
    "\n",
    "y_test = test_dataset['Churn']          \n",
    "X_test = test_dataset.drop(['Churn'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a7185",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per il training utilizzo la logistic regression\n",
    "\n",
    "lr_model = LogisticRegression(random_state=0, max_iter = 10000)\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "accuracy_lr = lr_model.score(X_test,y_test)\n",
    "\n",
    "print(lr_model)\n",
    "print('\\n')\n",
    "print(\"Accuracy: {:.3f}%\".format(accuracy_lr*100))\n",
    "\n",
    "print('\\n')\n",
    "cm_lr = confusion_matrix(y_test,lr_model.predict(X_test))\n",
    "f, ax = plt.subplots(figsize = (5,5))\n",
    "sns.heatmap(cm_lr, annot = True, linewidths = 0.5, color = \"red\", fmt = \".0f\", ax=ax)\n",
    "plt.xlabel(\"y_predicted\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.title(\"Confusion Matrix of Logistic Regression\")\n",
    "plt.show()\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
