{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d443e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efde3ac",
   "metadata": {},
   "source": [
    "# Importo dataset di train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d52d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"train.csv\")\n",
    "test_dataset = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782eb2ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non vi sono valori nulli nel dataset\n",
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60395b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non vi sono valori nulli nel dataset\n",
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11aab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check on null values\n",
    "train_dataset.isna().sum()\n",
    "test_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e20221",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customerId è unico per ogni riga, quindi non influenza 'Churn' per questo motivo possiamo dropparlo\n",
    "train_dataset = train_dataset.drop('customerID', axis=1)\n",
    "test_dataset = test_dataset.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf70a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a86672",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non sembra che gender influenzi il risultato, però prima di dropparlo faccio l'encoding dei dati e vedo la correlazione\n",
    "sns.countplot(x=train_dataset[\"gender\"],hue=train_dataset[\"Churn\"],palette='mako');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbc041",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaiamo un dizionario che associa ad ogni colonna del dataset i valori che può assumere la colonna\n",
    "def get_uniques(df, columns):\n",
    "    return {column: list(df[column].unique()) for column in columns}\n",
    "\n",
    "# nel dizionario lasciamo solo le colonne che hanno valori di tipo \"object\", quindi escludiamo i valori numerici\n",
    "# poiché in questa parte ci occupiamo dell'encoding, quindi i valori numerici sono già ok\n",
    "def get_categorical_columns(df):\n",
    "    return [column for column in df.columns if df.dtypes[column] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e27a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_uniques(train_dataset, get_categorical_columns(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4431bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Total charges' è una colonna che contiene numeri ma sono encoded come stringhe, devono essere convertiti\n",
    "# train_dataset['TotalCharges'].astype(np.float), questo comando da un errore perché non tutti i valori presenti nella colonna\n",
    "# sono numeri encoded come stringhe, ci sono dei valori nulli rappresentati come spazi ''\n",
    "sorted(train_dataset['TotalCharges'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sostituisco le stringhe vuote con valori nulli\n",
    "train_dataset['TotalCharges'] = train_dataset['TotalCharges'].replace(' ', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conto quanti righe presentano il valore null per capire come trattare la colonna\n",
    "train_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i valori nulli sono pochi rispetto al numero totale di righe, posso droppare queste righe\n",
    "train_dataset.dropna(how = 'any', inplace = True)\n",
    "\n",
    "# adesso le stringhe possono essere trasformate in float\n",
    "train_dataset['TotalCharges'] = train_dataset['TotalCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripeto tutto anche per il test_dataset\n",
    "get_uniques(test_dataset, get_categorical_columns(test_dataset))\n",
    "\n",
    "# sostituisco le stringhe vuote con valori nulli\n",
    "test_dataset['TotalCharges'] = test_dataset['TotalCharges'].replace(' ', np.NaN)\n",
    "\n",
    "# conto quanti righe presentano il valore null per capire come trattare la colonna\n",
    "test_dataset.isna().sum()\n",
    "\n",
    "# i valori sono in tutto 3, è un valore piccolo rispetto al numero totale di righe, posso droppare queste righe\n",
    "test_dataset.dropna(how = 'any', inplace = True)\n",
    "\n",
    "# adesso le stringhe possono essere trasformate in float\n",
    "test_dataset['TotalCharges'] = test_dataset['TotalCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaff2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_uniques(train_dataset, get_categorical_columns(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b058b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_uniques(test_dataset, get_categorical_columns(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14603c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nelle colonne 'MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies'\n",
    "# compaiono 3 possibili valori 'No, Yes, No internet service/ No phone service', non avere 'phone service o internet service' equivale\n",
    "# a non avere il servizio specifico, per cui si possono accorpare\n",
    "\n",
    "train_dataset['MultipleLines'] = train_dataset['MultipleLines'].replace('No phone service', 'No')\n",
    "\n",
    "train_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "      'TechSupport', 'StreamingTV', 'StreamingMovies']] = train_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                                                                'TechSupport', 'StreamingTV', 'StreamingMovies']].replace('No internet service', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faccio lo stesso per il test_dataset\n",
    "\n",
    "test_dataset['MultipleLines'] = test_dataset['MultipleLines'].replace('No phone service', 'No')\n",
    "\n",
    "test_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "      'TechSupport', 'StreamingTV', 'StreamingMovies']] = test_dataset[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                                                                'TechSupport', 'StreamingTV', 'StreamingMovies']].replace('No internet service', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divido le feature in due categorie per fare l'encoding, quelle binarie e quelle non binarie\n",
    "# con le prime userò label encoding mentre con le altre one hot\n",
    "\n",
    "binary_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                   'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']\n",
    "\n",
    "nominal_features = ['InternetService', 'Contract','PaymentMethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e97210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding per features binarie nel test e train dataset\n",
    "\n",
    "labelEncoder_X = LabelEncoder()\n",
    "for element in binary_features:\n",
    "    train_dataset[element] = labelEncoder_X.fit_transform(train_dataset[element])\n",
    "\n",
    "for element in binary_features:\n",
    "    test_dataset[element] = labelEncoder_X.fit_transform(test_dataset[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01421324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per il one hot encode per le features non binarie\n",
    "def onehot_encode(df, column):\n",
    "    df = df.copy()\n",
    "    dummies = pd.get_dummies(df[column])\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(column, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3da157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding per features non binarie nel test e train dataset\n",
    "\n",
    "for feature in nominal_features:\n",
    "    train_dataset = onehot_encode(train_dataset, feature)\n",
    "\n",
    "for feature in nominal_features:\n",
    "    test_dataset = onehot_encode(test_dataset, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ea0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdadc57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# una volta fatto l'encoding è possibile visualizzare l'heatmap con tutte le feature\n",
    "# per capire se vi sono altre colonne che è possibile droppare vediamo la correlazione tra le diverse colonne\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "correlation = train_dataset.corr()\n",
    "sns.heatmap(correlation, annot = True, linewidth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f317a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop gender column, la correlazione è bassa, quindi viene confermato che il gender non influenza il risultato\n",
    "train_dataset = train_dataset.drop('gender', axis=1)\n",
    "test_dataset = test_dataset.drop('gender', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a308f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la correlazione tra la colonna \"TotalCharges\" e \"Tenure\" è alta, droppo quella che ha valore di correlazione minore con \"churn\"\n",
    "train_dataset = train_dataset.drop('TotalCharges', axis=1)\n",
    "test_dataset = test_dataset.drop('TotalCharges', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaed390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la correlazione con churn è prossima allo zero, non sembra che 'phone Service' influenzi il risultato finale\n",
    "train_dataset = train_dataset.drop('PhoneService', axis=1)\n",
    "test_dataset = test_dataset.drop('PhoneService', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df7cd6",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_dataset['Churn']          \n",
    "X_train = train_dataset.drop(['Churn'], axis=1)  \n",
    "\n",
    "y_test = test_dataset['Churn']          \n",
    "X_test = test_dataset.drop(['Churn'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a7185",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per il training utilizzo la logistic regression\n",
    "\n",
    "lr_model = LogisticRegression(random_state=0, max_iter = 20000)\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "accuracy_lr = lr_model.score(X_test,y_test)\n",
    "\n",
    "print(lr_model)\n",
    "print('\\n')\n",
    "print(\"Accuracy: {:.3f}%\".format(accuracy_lr*100))\n",
    "\n",
    "print('\\n')\n",
    "cm_lr = confusion_matrix(y_test,lr_model.predict(X_test))\n",
    "f, ax = plt.subplots(figsize = (5,5))\n",
    "sns.heatmap(cm_lr, annot = True, linewidths = 0.5, color = \"red\", fmt = \".0f\", ax=ax)\n",
    "plt.xlabel(\"y_predicted\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.title(\"Confusion Matrix of Logistic Regression\")\n",
    "plt.show()\n",
    "print('\\n\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f74ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# numero di yes e no per churn, dove yes=1 e no=1\n",
    "sns.countplot(x=train_dataset[\"Churn\"],palette='mako');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87fe91e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# numero di yes e no per churn, dove yes=1 e no=1\n",
    "sns.countplot(x=test_dataset[\"Churn\"],palette='mako');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bf2007",
   "metadata": {},
   "source": [
    "la precision e la recall per la classificazione degli \"yes\" sono particolarmente basse, come si può notare anche dalla confusion matrix (sia quella per la regression che per l'albero), questo però potrebbe essere dato dal fatto che il numero di esempi per \"yes\" è nettamente minore di quelli per \"no\", quindi potrebbero non essere sufficienti per addrestrare correttamente il modello"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
